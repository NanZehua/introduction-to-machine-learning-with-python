# 必要的库和工具

```
pip3 install numpy scipy matplotlib ipython scikit-learn pandas mglearn
```

## Jupyter Notebook

```
python3 -m pip install --upgrade pip
python3 -m pip install jupyter
jupyter notebook
```

## NumPy

常用多维数组：

```
import numpy as np

x = np.array([
    [1, 2, 3], [4, 5,6 ]
])

print("x:\n{}".format(x))
```

```
x:
[[1 2 3]
 [4 5 6]]
```

## SciPy

稠密转稀疏：

```
from scipy import sparse
import numpy as np

# 创建一个二维NumPy数组，对角线为1，其余都为0 eye = np.eye(4)
eye = np.eye(4)
print("NumPy array:\n{}".format(eye))

# 将NumPy数组转换为CSR格式的SciPy稀疏矩阵
# 只保存非零元素
sparse_matrix = sparse.csr_matrix(eye)
print("\nSciPy sparse CSR matrix:\n{}".format(sparse_matrix))
```

直接创建稀疏：

```
import numpy as np
from scipy import sparse

# 创建[1. 1. 1. 1.]
data = np.ones(4)

# 创建[0 1 2 3]
row_indices = np.arange(4)
# 创建[0 1 2 3]
col_indices = np.arange(4)
# 直接创建稀疏矩阵，仅提供非0的格子与存储的数据
eye_coo = sparse.coo_matrix((data, (row_indices, col_indices)))
print("COO representation:\n{}".format(eye_coo))
```

## matplotlib

科学绘图库

```
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt

# 在-10和10之间生成一个数列，共100个数
x = np.linspace(-10, 10, 100)
# 用正弦函数创建每个x的y值
y = np.sin(x)
# plot函数绘制一个数组关于另一个数组的折线图 (marker="x"看起来是用字母x在曲线上标记一下而已)
plt.plot(x, y, marker="x")
```

## pandas

操作表格的库

```
import pandas as pd
from IPython.display import display

# 创建关于人的简单数据集
data = {
    'Name': ["John", "Anna", "Peter", "Linda"],
    'Location' : ["New York", "Paris", "Berlin", "London"],
    'Age' : [24, 13, 53, 33]
}

# 创建表格
data_pandas = pd.DataFrame(data)

# 打印表格
display(data_pandas)
```

# 第一个应用:鸢尾花分类

## 初识数据

```
from sklearn.datasets import load_iris

iris_dataset = load_iris()

# 数据集包含了哪些信息
print("Keys of iris_dataset: \n{}".format(iris_dataset.keys()))
# 数据集的描述信息DESCR
print(iris_dataset.DESCR[:108])
# 数据集包含了3个品种，也就是分类
print(iris_dataset.target_names)
# 数据集的特征列表
print(iris_dataset.feature_names)
# 样本数据在data里，是numpy的array，其中shape记录了有多少样本，每行样本有几个属性
print(type(iris_dataset.data), iris_dataset.data.shape)
# 样本数据
print(iris_dataset.data[:5])
# 分类数据在target里，也是numpy array
print(iris_dataset.target)
```

## 训练数据与测试数据

切分样本

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

iris_dataset = load_iris()

X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)
```

## 观察数据

检查数据，看是否有异常的数据和特殊值，通过组合每2个特征+分类绘制一个散点图的矩阵。

可以从散点图看出，特征与分类具备明显的关联性。

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import pandas as pd
import mglearn

iris_dataset = load_iris()

X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

# 利用X_train中的数据创建DataFrame
# 利用iris_dataset.feature_names中的字符串对数据列进行标记
iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)
# 利用DataFrame创建散点图矩阵，按y_train着色
grr = pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o', 
                        hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)
```

## 训练第一个模型：K邻近分类算法

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

iris_dataset = load_iris()

# 切分75%的训练集和25%的测试集, 随机打乱数据的种子固定为0
X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

# K邻近分类器, 算法取最近1个点的标签作为分类
knn = KNeighborsClassifier(n_neighbors=1)
# 训练模型
knn.fit(X_train, y_train)
```

## 做出预测

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

iris_dataset = load_iris()

# 切分75%的训练集和25%的测试集, 随机打乱数据的种子固定为0
X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

# K邻近分类器, 算法取最近1个点的标签作为分类
knn = KNeighborsClassifier(n_neighbors=1)
# 训练模型
knn.fit(X_train, y_train)

# 构造一个测试的数据, 需要作为一行放在矩阵里
X_new = np.array([[5, 2.9, 1, 0.2]])
# 预测分类
y_new = knn.predict(X_new)
# 分类是整形
print(y_new)
# 对应成分类的名字
print(iris_dataset.target_names[y_new])
```

## 评估模型

```
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

iris_dataset = load_iris()

# 切分75%的训练集和25%的测试集, 随机打乱数据的种子固定为0
X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)

# K邻近分类器, 算法取最近1个点的标签作为分类
knn = KNeighborsClassifier(n_neighbors=1)
# 训练模型
knn.fit(X_train, y_train)

# 在测试集做预测
y_pred = knn.predict(X_test)
# 计算预测的精度, 其中y_pred==y_test得到的是一个bool向量, np.mean返回True的比例
print(np.mean(y_pred == y_test))
# 也可以直接用模型的score方法完成预测+精度计算
print(knn.score(X_test, y_test))
```

# 小结

* 监督学习与非监督学习
* 可能的品种叫做"分类"，具体每个样本的品种就叫做"标签"
* 数据集需互划分为训练集和测试集
* 数据集包括了X和y，其中X是特征的二维数组，y是标签的一维数组
* 本章用到了scikit-learn中任何机器学习算法的核心方法：fit、predict、score