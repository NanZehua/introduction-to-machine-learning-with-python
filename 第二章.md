# 分类与回归

分类是预测标签，包括二分类与多分类。

回归是预测连续值，比如预测收入、房价。

# 泛化、过拟合与欠拟合

随着模型算法逐渐复杂，其在训练集上的预测精度将提高，但在测试集上的预测精度将降低，因此模型的复杂度需要折衷。

模型过于复杂，将导致模型泛化能力差，即过拟合。
模型过于简单，将导致模型精度在训练集表现就很差，更不用说测试集的表现了，此时即欠拟合。

## 模型复杂度与数据集大小的关系

数据点的值变化范围越大，则可以应用更加复杂的模型，预测的表现也会越好。

更多的训练数据往往伴随着更大范围的特征值变化，因此可以应用更复杂的模型算法。

但注意，如果是非常类似的数据点，无论数据集多大也是无济于事的。

# 样本数据说明

## 2个低维度数据集

这两个数据集很小，特征维度很低，不超过2维。

用于分类的forge数据集，2个特征输入。

```
import mglearn
import matplotlib.pyplot as plt

# 生成forge样本的特征X和目标y
X, y = mglearn.datasets.make_forge()

# 使用样本的第0列特征和第1列特征作为绘制的横坐标和纵坐标，目标y作为图案
mglearn.discrete_scatter(X[:, 0], X[:, 1], y)
# 在右下角画一个图案的文字说明，即2个分类
plt.legend(["Class 0", "Class 1"], loc=4) 
# 绘制横坐标的说明
plt.xlabel("First feature")
# 绘制纵坐标的说明
plt.ylabel("Second feature")
# 样本的个数和特征的维度
print("X.shape: {}".format(X.shape))
```

用于回归的wave数据集，1个特征输入。

```
import mglearn
import matplotlib.pyplot as plt

#构造40个样本
X, y = mglearn.datasets.make_wave(n_samples=40)
#因为X只有1维, 所以直接可以画散点图
plt.plot(X, y, 'o')
#y的连续值范围
plt.ylim(-3, 3)
# 画横坐标说明
plt.xlabel("Feature")
# 画纵坐标说明
plt.ylabel("Target")
```

## 2个高维度数据集

用于分类的cancer癌症数据集，569个样本，30维特征。

```
from sklearn.datasets import load_breast_cancer
import numpy as np

# 加载数据集
cancer = load_breast_cancer()
# 打印样本规模和特征规模
print(cancer.data.shape)
# 打印不同分类的样本数量, np.bincount统计不同分类的个数, 然后与分类的名字做1:1 zip，得到每个分类的样本数量
print("Sample counts per class:\n{}".format(
{n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))
```

```
(569, 30)
Sample counts per class:
{'malignant': 212, 'benign': 357}
```


用于回归的boston房价数据集。

```
from sklearn.datasets import load_boston
boston = load_boston()
print("Data shape: {}".format(boston.data.shape))
```

以及对原有特征经过简单的"特征工程"，增加了若干组合特征，得到的extened_boston房价数据集：

```
from sklearn.datasets import load_boston
X, y = mglearn.datasets.load_extended_boston()
print("X.shape: {}".format(X.shape))
```
