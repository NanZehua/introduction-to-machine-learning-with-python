# 降维、特征提取与流行学习

## 主成分分析

PCA可以从已有特征产生出新特征，新特征对解释数据更好用。

PCA可以指定提取的特征个数，实现降维的目的。

### 可视化用途

下面对cancer数据集利用PCA从30个维降到2个维度

```
from sklearn.decomposition import PCA
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler

#  数据集
cancer = load_breast_cancer()

# 标准化
scaler = StandardScaler()
scaler.fit(cancer.data)
X_scaled = scaler.transform(cancer.data)

# 降维到2的PCA
pca = PCA(n_components=2)
# 训练PCA
pca.fit(X_scaled)
# 进行特征提取变换
X_pca = pca.transform(X_scaled)
# 降维前的特征个数
print("Original shape: {}".format(str(X_scaled.shape))) 
# 降维后的特征个数
print("Reduced shape: {}".format(str(X_pca.shape)))
```

```
Original shape: (569, 30)
Reduced shape: (569, 2)
```

因为PCA后只有2个特征维度，所以可以绘图做可视化分析。

### 主成分提取用途

图像分类场景，因为图片特征都是像素点，只有把所有像素整体看待才有意义，所以图像特征经过PCA处理后精度会更好。

```
from sklearn.datasets import fetch_lfw_people
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# 加载数据
people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)

# 3023张人脸照片作为样本输入
print("people.images.shape: {}".format(people.images.shape))
# 3023张图片对应的人名
print("Number of classes: {}".format(len(people.target_names)))

# 3023列的false向量
mask = np.zeros(people.target.shape, dtype=np.bool)

# 遍历所有的分类(也就是人名，target取值是0~61)
# 每个分类保留50个样本
for target in np.unique(people.target):
    mask[np.where(people.target == target)[0][:50]] = True
X_people = people.data[mask]  # data是已经把每张图片n*m的2维压成1维的数据格式
y_people = people.target[mask]

# 现在留下的样本，每个人不会超过50张

# 特征缩放到0~1之间, 因为是RGB颜色
X_people = X_people / 255

# 切分数据
#print(X_people, y_people)
X_train, X_test, y_train, y_test = train_test_split(
    X_people, y_people, stratify=y_people, random_state=0)

# KNN分类, 最近邻分类(只考虑最近的节点)
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)

print(knn.score(X_test, y_test))
```

```
0.23255813953488372
```

精度不高，尝试通过PCA提取100个主成分作为新特征。

```
from sklearn.datasets import fetch_lfw_people
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA

# 加载数据
people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)

# 3023张人脸照片作为样本输入
print("people.images.shape: {}".format(people.images.shape))
# 3023张图片对应的人名
print("Number of classes: {}".format(len(people.target_names)))

# 3023列的false向量
mask = np.zeros(people.target.shape, dtype=np.bool)

# 遍历所有的分类(也就是人名，target取值是0~61)
# 每个分类保留50个样本
for target in np.unique(people.target):
    mask[np.where(people.target == target)[0][:50]] = True
X_people = people.data[mask]  # data是已经把每张图片n*m的2维压成1维的数据格式
y_people = people.target[mask]

# 现在留下的样本，每个人不会超过50张

# 特征缩放到0~1之间, 因为是RGB颜色
X_people = X_people / 255

# 切分数据
#print(X_people, y_people)
X_train, X_test, y_train, y_test = train_test_split(
    X_people, y_people, stratify=y_people, random_state=0)

# PCA提取100个主成分作为新的特征, 基于训练集fit, 应用到训练集和测试集
pca = PCA(n_components=100, whiten=True, random_state=0).fit(X_train)
X_train_pca = pca.transform(X_train)
X_test_pca = pca.transform(X_test)
print("X_train_pca.shape: {}".format(X_train_pca.shape))

# KNN分类, 最近邻分类(只考虑最近的节点)
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train_pca, y_train)

# 精度
print(knn.score(X_test_pca, y_test))
```

```
0.312015503875969
```

PCA通过提取主成分作为新特征带来了精度提升。

