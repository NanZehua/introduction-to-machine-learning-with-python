# 处理机器学习问题

模型构建的完整流程是：收集新数据、清洗数据、构建模型、分析模型。

机器学习只是其中的一小部分，我们首先要明确要解决什么问题，如何衡量它是成功的，以及能够带来什么收益。

一个常见的错误就是：认为网格搜索调参的回报是更高的，然而实际上更好的特征与规划才会使机器学习更加高效。

有些场景需要很高的精度，单靠机器学习算法可能无法达到，那么此时机器学习的意义就是减少响应时间、降低成本，其他的重新交给人来做决定。

# 从原型到生产

将算法部署到一个更大的系统中，涉及的是软件工程的方方面面，比如：可靠性、可预测性、运行时间、内存需求。

经验就是：保持简单，降低复杂度。

# 测试生产系统

之前我们都是基于事先收集的测试集来评估算法的精度，这是离线评估。

当我们的机器学习系统是面向用户时，就需要采用A/B测试，这是一种盲测用户研究形式。

一部分用户应用A算法，另一部分应用B算法，然后在一段时间内记录相关的指标，然后我们就可以根据实际用户情况对两种算法进行选择。

通常来说，A是一个新模型，B是一个已建立的系统。

# 下一步怎么走

如果像进一步提高机器学习技能，那么参考下面的建议。

## 理论


本书试图直观的解释大多数机器学习算法的工作原理，但模型背后都是概率论、线性代数、最优化方面的理论。

推荐3本书：
* 《统计学习基础》
* Machine Learning: An Algorithmic Perspective
* Machine Learning: A Probabilistic Perspective


## 其他机器学习框架和包

python很适合尝试与评估模型，但大型web服务和应用更常用java和c++编写，部署模型需与这些系统进行集成。

在集群上运行分布式运算的机器学习算法有一个常见解决方案是spark的mllib库。

## 排序、推荐系统与其他学习类型

机器学习有2个重要主题没有包含在本书：

* 排序问题：检索出按相关性排序的答案。
* 推荐系统：根据用户偏好提供内容。

## 概率建模、推断与概率编程

忽略

## 神经网络

比如Alpha go围棋战胜人类冠军、语音理解的性能不断提高，接近实时的语音翻译，这些领域发展非常迅速，以及当前对最新进展的任何参考都很快就过时了，可以读一下新书《Deep Learning》。

## 推广到更大的数据集

如果我们需要处理TB级的数据，那么有2种解决策略：

* 核外学习
* 集群上的并行化

核外学习仍旧是单机运算，但是数据是从硬盘或者网络分块读入内存进行计算，模型更新后将数据从内存中淘汰，再读入下一批数据块。

scikit-learn有一些模型实现了核外学习，但是因为仍旧是单机实现，所以在大数据集上运行仍旧很慢。

集群并行最常用的方法是spark的mllib，数据放在hadoop中。

## 磨练你的技术

只有实践才能让你成为本书介绍主题的专家。

对于不同的任务与不同的数据集，特征提取，预处理，可视化和模型构建差异可能都很大。

可以参与kaggle比赛来练习，另外openml平台也提供了很多数据集和任务。

定义问题和收集数据是现实世界问题的重要方面，用正确的方式表示问题可能比努力提高分类器精度的最后一个百分点要重要的多。

# 总结

希望已经让你相信了机器学习在应用中的实用性，以及在实践中实现机器学习的简单行。

继续挖掘数据，同时不要忽略大局。