# 交叉验证

我们知道用训练集fit模型，用测试集验证泛化能力的套路。

```
from sklearn.datasets import make_blobs
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# 创建一个模拟数据集
X, y = make_blobs(random_state=0)

# 将数据和标签划分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) # 将模型实例化，并用它来拟合训练集
logreg = LogisticRegression().fit(X_train, y_train)

# 在测试集上评估该模型
print("Test set score: {:.2f}".format(logreg.score(X_test, y_test)))
```

```
Test set score: 0.88
```

单次划分数据集并不稳定和全面，因此我们需要对数据集进行多次划分，训练多个模型进行综合评估，这叫"交叉验证"。

## K折交叉

最常见的就是"K折交叉验证"，将数据均匀划分成K份，每次用1份做测试集，剩余做训练集。

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# 数据集
iris = load_iris()

# 模型
logreg = LogisticRegression()

# K折交叉验证
scores = cross_val_score(logreg, iris.data, iris.target, cv=3)
print("Cross-validation scores: {}".format(scores))
print("Average cross-validation score: {:.2f}".format(scores.mean()))
```

```
Cross-validation scores: [0.96078431 0.92156863 0.95833333]
Average cross-validation score: 0.95
```

上述数据集分成3折，训练了3次模型，得到了3个精度，以及平均精度。

## 分层K折交叉

K折交叉划分数据的方式是从头开始均分成K份，如果样本数据的分类分布不均匀，那么就会导致K折交叉策略失效，比如：

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

# 数据集
iris = load_iris()
print("Iris labels:\n{}".format(iris.target))
```

```
Iris labels:
     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 000000000000111111111111111111111111 1 111111111111111111111111122222222222 2 222222222222222222222222222222222222 2 2]
```

显然样本数据的分类没有打散，可能测试集全是分类2，而训练集里压根没出现过分类2.

sklearn会根据模型是回归还是分类决定使用标准K折还是分层K折，不需我们关心，只需要了解。

## 其他策略

K折还有其他策略，通过cv参数控制即可，比如：留1验证。

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import ShuffleSplit,cross_val_score

# 数据集
iris = load_iris()

# 模型
logreg = LogisticRegression()

# 打乱划分交叉
shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)
scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)
print("Cross-validation scores: {}".format(scores))
print("Average cross-validation score: {:.2f}".format(scores.mean()))
```

```
Cross-validation scores: [0.90666667 0.92       0.96       0.98666667 0.98666667 0.96
 0.92       0.89333333 0.81333333 0.89333333]
Average cross-validation score: 0.92
```

通过cv参数控制策略，ShuffleSplit是运行10次，每次随机抽取50%的为训练集，50%的为测试集。

# 网格搜索

利用网格搜索，实现模型的自动化调参，找到最佳泛化性能的参数。

## 带交叉验证的网格搜索

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC

# 数据集
iris = load_iris()

# 切分数据
X_train, X_test, y_train, y_test = train_test_split(
         iris.data, iris.target, random_state=0)

# 2种网格
param_grid = [
    # 第1个网格
    {'kernel': ['rbf'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},
    # 第2个网格
    {'kernel': ['linear'],'C': [0.001, 0.01, 0.1, 1, 10, 100]}
]
# 在2个网格中, 找到SVC模型的最佳参数, 这里cv=5表示每一种参数组合进行5折交叉验证计算得分
grid_search = GridSearchCV(SVC(), param_grid, cv=5)

# fit找到最佳泛化的参数
grid_search.fit(X_train, y_train)

# 查看精度
print("泛化精度:", grid_search.score(X_test, y_test))

# 打印最佳参数
print("Best parameters: {}".format(grid_search.best_params_))
```

```
泛化精度: 0.9736842105263158
Best parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
```

实际上，X_train数据会被网格进一步切分成2部分，一部分是训练集、一部分是验证集。 

最终，我们还是基于测试集X_test来看模型对于未知数据的泛化能力。


## 交叉验证+网格搜索的嵌套

可以采用先交叉划分数据集，再进行K折网格搜索，这就是嵌套的意思。

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.svm import SVC

# 数据集
iris = load_iris()

# 2种网格
param_grid = [
    # 第1个网格
    {'kernel': ['rbf'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},
    # 第2个网格
    {'kernel': ['linear'],'C': [0.001, 0.01, 0.1, 1, 10, 100]}
]
# 在2个网格中, 找到SVC模型的最佳参数, 每一组参数进行5折评估
grid_search = GridSearchCV(SVC(), param_grid, cv=5)

# 外层K折
scores = cross_val_score(grid_search, iris.data, iris.target, cv=5)

# 打印精度
print(scores)
```

主要用来评估一下网格搜索到的最佳参数可以达到的最好泛化精度：

```
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from sklearn.svm import SVC

# 数据集
iris = load_iris()

# 2种网格
param_grid = [
    # 第1个网格
    {'kernel': ['rbf'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},
    # 第2个网格
    {'kernel': ['linear'],'C': [0.001, 0.01, 0.1, 1, 10, 100]}
]
# 在2个网格中, 找到SVC模型的最佳参数, 每一组参数进行5折评估
grid_search = GridSearchCV(SVC(), param_grid, cv=5)

# 外层K折
scores = cross_val_score(grid_search, iris.data, iris.target, cv=5)

# 打印精度
print(scores)
```

```
[0.96666667 1.         0.9        0.96666667 1.        ]
```