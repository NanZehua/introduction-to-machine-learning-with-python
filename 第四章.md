# 分类变量

如果特征不是连续值，而是一些分类特征，来自一系列固定的可能取值，那么直接用于类似Logistic回归分类模型是没有意义的。

## One-Hot编码（虚拟变量）

将1个特征的多种取值，改为多个特征的0/1取值，其中有一个特征为1，其他为0.

```
from sklearn.preprocessing import OneHotEncoder

# fit训练one hot, 返回非稀疏矩阵, 当transform时遇到没见过的特征值则对应one-hot编码全部为0
enc = OneHotEncoder(sparse=False, handle_unknown='ignore')
X = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]
enc.fit(X)    

# one-hot编码新数据
X_one_hot = enc.transform([[1,4,2]])    
print(X_one_hot)
```

```
[[0. 1. 0. 0. 0. 0. 0. 1. 0.]]
```

第1个特征取值有2个（0、1），所以在one-hot里占用2列；第2个特征取值有3个（0、1、2），所以在one-hot里占用3列；第3个特征取值有4个（0、1、2、3），所以one-hot占用4列；

对于输入特征[1,4,2]，因为4在fit时没有出现过，所以在one-hot编码中被ignore为3个0.

### 数字可以编码分类变量

书中提到pandas库做one-hot的时候，可以指定对哪些特征对one-hot，而对其他连续特征可以不做处理。

我以sklearn为例，假设3维特征只有前2个特征是离散分类需要做one-hot，而第3个特征不需要one-hot。

```
from sklearn.preprocessing import OneHotEncoder

# fit训练one hot, 返回非稀疏矩阵, 当transform时遇到没见过的特征值则对应one-hot编码全部为0
enc = OneHotEncoder(categorical_features=[0,1], sparse=False, handle_unknown='ignore')
X = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]
enc.fit(X)    

# one-hot编码新数据
X_one_hot = enc.transform([[1,4,2]])    
print(X_one_hot)
```

```
[[0. 1. 0. 0. 0. 2.]]
```

通过categorical_features=[0,1]指定了只有前2个特征需要离散化。

从结果可见，0,1是第1列特征的one-hot，0,0,0是第2列特征的one-hot（因为4在fit时不存在），第3列特征没有变动。

